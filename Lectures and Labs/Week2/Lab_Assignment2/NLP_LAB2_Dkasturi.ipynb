{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6651e666",
   "metadata": {},
   "source": [
    "Steps to follow : \n",
    "1) tokenize text.\n",
    "\n",
    "2) convert tokens into lowercase\n",
    "\n",
    "3) With Raw Frequency\n",
    "\n",
    "    a) create bigram finder and scorer\n",
    "\n",
    "    b) apply re filter for to remove non-alphanumeric tokens\n",
    "\n",
    "    c) remove stopwords  \n",
    "\n",
    "    d) remove low frequency words\n",
    "\n",
    "4) repeat steps a-d with pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "459c04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0377ddea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149201\n",
      "\n",
      "\n",
      "['[', 'leaves', 'of', 'grass', 'by', 'walt', 'whitman', '1855', ']', 'come', ',', 'said', 'my', 'soul', ',', 'such', 'verses', 'for', 'my', 'body', 'let', 'us', 'write', ',', '(', 'for', 'we', 'are', 'one', ',', ')', 'that', 'should', 'i', 'after', 'return', ',', 'or', ',', 'long', ',', 'long', 'hence', ',', 'in', 'other', 'spheres', ',', 'there', 'to', 'some', 'group', 'of', 'mates', 'the', 'chants', 'resuming', ',', '(', 'tallying', 'earth', \"'s\", 'soil', ',', 'trees', ',', 'winds', ',', 'tumultuous', 'waves', ',', ')', 'ever', 'with', 'pleas', \"'d\", 'smile', 'i', 'may', 'keep', 'on', ',', 'ever', 'and', 'ever', 'yet', 'the', 'verses', 'owning', '--', 'as', ',', 'first', ',', 'i', 'here', 'and', 'now', 'signing', 'for']\n"
     ]
    }
   ],
   "source": [
    "file17 = nltk.corpus.gutenberg.fileids()[17]\n",
    "leavestext = nltk.corpus.gutenberg.raw(file17)\n",
    "leavestokens = nltk.word_tokenize(leavestext)\n",
    "leaveswords = [x.lower() for x in leavestokens]\n",
    "\n",
    "print(len(leaveswords))\n",
    "print('\\n')\n",
    "print(leaveswords[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c9ec07",
   "metadata": {},
   "source": [
    "## For raw frequency : ##\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f87b51",
   "metadata": {},
   "source": [
    "### Bigram finder and scorer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7cabd867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'the'), 0.014785423690189745)\n",
      "(('of', 'the'), 0.008458388348603562)\n",
      "((',', 'and'), 0.008404769405030797)\n",
      "((',', 'i'), 0.006762689258114892)\n",
      "(('in', 'the'), 0.004054932607690297)\n",
      "(('and', 'the'), 0.0037064094744673295)\n",
      "((',', '('), 0.002292209837735672)\n",
      "((',', 'to'), 0.0020442222237116374)\n",
      "(('to', 'the'), 0.002037519855765042)\n",
      "((',', 'or'), 0.002004008016032064)\n",
      "(('me', ','), 0.001977198544245682)\n",
      "(('i', 'see'), 0.0019570914404058956)\n",
      "(('on', 'the'), 0.0018096393455807936)\n",
      "((\"'d\", ','), 0.0018029369776341982)\n",
      "((',', 'with'), 0.0016688896187022875)\n",
      "(('from', 'the'), 0.0016487825148625008)\n",
      "(('you', ','), 0.0014678185803044216)\n",
      "((',', 'but'), 0.0014477114764646349)\n",
      "((',', ')'), 0.0014276043726248484)\n",
      "(('it', 'is'), 0.001333771221372511)\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(leaveswords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "for bscore in scored[:20]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dce27e",
   "metadata": {},
   "source": [
    "#### Filters: ####\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b2222b",
   "metadata": {},
   "source": [
    "##### a) removing non-alphabetical words #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "24c20e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 0.008458388348603562)\n",
      "(('in', 'the'), 0.004054932607690297)\n",
      "(('and', 'the'), 0.0037064094744673295)\n",
      "(('to', 'the'), 0.002037519855765042)\n",
      "(('i', 'see'), 0.0019570914404058956)\n",
      "(('on', 'the'), 0.0018096393455807936)\n",
      "(('from', 'the'), 0.0016487825148625008)\n",
      "(('it', 'is'), 0.001333771221372511)\n",
      "(('with', 'the'), 0.0013002593816395334)\n",
      "(('i', 'am'), 0.0012801522777997466)\n",
      "(('to', 'me'), 0.0011729143906542181)\n",
      "(('all', 'the'), 0.0011058907111882628)\n",
      "(('by', 'the'), 0.00100535519198933)\n",
      "(('out', 'of'), 0.0009986528240427343)\n",
      "(('the', 'earth'), 0.0009785457202029478)\n",
      "(('see', 'the'), 0.0009048196727903968)\n",
      "(('do', 'not'), 0.0008512007292176325)\n",
      "(('of', 'my'), 0.0008512007292176325)\n",
      "(('of', 'all'), 0.0007908794176982728)\n",
      "(('and', 'i'), 0.0007841770497516772)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#creating a function for non-alphabetic characters:\n",
    "\n",
    "def alpha_filter(w):\n",
    "    pattern = re.compile('^[^a-z]+$') # pattern for non-alphabetical characters\n",
    "    if pattern.match(w):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Applying filter to remove non-alphabetical tokens from bigram    \n",
    "finder.apply_word_filter(alpha_filter)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "for bscore in scored[:20]:\n",
    "    print(bscore) #the values now make more sense\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e165a",
   "metadata": {},
   "source": [
    "##### b) filter to remove stopwords: #####\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "812f00fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n",
      "(('young', 'men'), 0.0002077734063444615)\n",
      "(('every', 'one'), 0.00016085683071829279)\n",
      "(('old', 'age'), 0.00014745209482510172)\n",
      "(('young', 'man'), 0.00014745209482510172)\n",
      "(('old', 'man'), 0.00011394025509212404)\n",
      "(('open', 'air'), 0.00011394025509212404)\n",
      "(('every', 'day'), 9.383315125233744e-05)\n",
      "(('every', 'thing'), 9.383315125233744e-05)\n",
      "(('whole', 'earth'), 8.042841535914639e-05)\n",
      "(('new', 'world'), 7.372604741255086e-05)\n",
      "(('one', 'side'), 6.702367946595533e-05)\n",
      "(('thousand', 'years'), 6.702367946595533e-05)\n",
      "(('let', 'others'), 6.032131151935979e-05)\n",
      "(('let', 'us'), 6.032131151935979e-05)\n",
      "(('little', 'child'), 6.032131151935979e-05)\n",
      "(('western', 'sea'), 6.032131151935979e-05)\n",
      "(('comes', 'back'), 5.3618943572764255e-05)\n",
      "(('old', 'men'), 5.3618943572764255e-05)\n",
      "(('walt', 'whitman'), 5.3618943572764255e-05)\n",
      "(('go', 'forth'), 4.691657562616872e-05)\n"
     ]
    }
   ],
   "source": [
    "# Getting stopwords from nltk\n",
    "nltkstopwords = nltk.corpus.stopwords.words('english')\n",
    "print(nltkstopwords[:20])\n",
    "\n",
    "#adding more stopwords to the list\n",
    "morestopwords = ['could','would','might','must','need','sha','wo','y',\"'s\",\"'d\",\"'ll\",\"'t\",\"'m\",\"'re\",\"'ve\", \"n't\"]\n",
    "stopwords = nltkstopwords + morestopwords\n",
    "\n",
    "#Applying filter to remove stopwords\n",
    "\n",
    "finder.apply_word_filter(alpha_filter)\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "for bscore in scored[:20]:\n",
    "    print(bscore) #The bigrams that are generated are more clear now and give a better context about the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1319a27a",
   "metadata": {},
   "source": [
    "##### c) Filter to remove low frequency words #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eb3e5891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('young', 'men'), 0.0002077734063444615)\n",
      "(('every', 'one'), 0.00016085683071829279)\n",
      "(('old', 'age'), 0.00014745209482510172)\n",
      "(('young', 'man'), 0.00014745209482510172)\n",
      "(('old', 'man'), 0.00011394025509212404)\n",
      "(('open', 'air'), 0.00011394025509212404)\n",
      "(('every', 'day'), 9.383315125233744e-05)\n",
      "(('every', 'thing'), 9.383315125233744e-05)\n",
      "(('whole', 'earth'), 8.042841535914639e-05)\n",
      "(('new', 'world'), 7.372604741255086e-05)\n",
      "(('one', 'side'), 6.702367946595533e-05)\n",
      "(('thousand', 'years'), 6.702367946595533e-05)\n",
      "(('let', 'others'), 6.032131151935979e-05)\n",
      "(('let', 'us'), 6.032131151935979e-05)\n",
      "(('little', 'child'), 6.032131151935979e-05)\n",
      "(('western', 'sea'), 6.032131151935979e-05)\n",
      "(('comes', 'back'), 5.3618943572764255e-05)\n",
      "(('old', 'men'), 5.3618943572764255e-05)\n",
      "(('walt', 'whitman'), 5.3618943572764255e-05)\n",
      "(('go', 'forth'), 4.691657562616872e-05)\n"
     ]
    }
   ],
   "source": [
    "finder.apply_freq_filter(6)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "for bscore in scored[:20]:\n",
    "    print(bscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1478b17b",
   "metadata": {},
   "source": [
    "## PMI ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e9f9e5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('abject', 'louse'), 17.186897679535367)\n",
      "(('abroad', 'swift-rising'), 17.186897679535367)\n",
      "(('accumulating', 'undirected'), 17.186897679535367)\n",
      "(('agnus', 'dei'), 17.186897679535367)\n",
      "(('ague', 'convulse'), 17.186897679535367)\n",
      "(('aimedst', 'highly'), 17.186897679535367)\n",
      "(('alexandrian', 'pharos'), 17.186897679535367)\n",
      "(('ambushes', 'opponents'), 17.186897679535367)\n",
      "(('andirons', 'straddle'), 17.186897679535367)\n",
      "(('artless', 'plaints'), 17.186897679535367)\n",
      "(('au', 'monde'), 17.186897679535367)\n",
      "(('balsamic', 'busses'), 17.186897679535367)\n",
      "(('beach-waves', 'combing'), 17.186897679535367)\n",
      "(('beaver', 'pats'), 17.186897679535367)\n",
      "(('behaving', 'licentious'), 17.186897679535367)\n",
      "(('bitterest', 'envy.'), 17.186897679535367)\n",
      "(('block', 'swags'), 17.186897679535367)\n",
      "(('bokh', 'horse-herd'), 17.186897679535367)\n",
      "(('brownish', 'woolen'), 17.186897679535367)\n",
      "(('bulging', 'store-house'), 17.186897679535367)\n"
     ]
    }
   ],
   "source": [
    "finder2 = BigramCollocationFinder.from_words(leaveswords)\n",
    "scored = finder2.score_ngrams(bigram_measures.pmi)\n",
    "\n",
    "for bscore in scored[:20]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a0b9579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('abject', 'louse'), 17.186897679535367)\n",
      "(('abroad', 'swift-rising'), 17.186897679535367)\n",
      "(('accumulating', 'undirected'), 17.186897679535367)\n",
      "(('agnus', 'dei'), 17.186897679535367)\n",
      "(('ague', 'convulse'), 17.186897679535367)\n",
      "(('aimedst', 'highly'), 17.186897679535367)\n",
      "(('alexandrian', 'pharos'), 17.186897679535367)\n",
      "(('ambushes', 'opponents'), 17.186897679535367)\n",
      "(('andirons', 'straddle'), 17.186897679535367)\n",
      "(('artless', 'plaints'), 17.186897679535367)\n",
      "(('au', 'monde'), 17.186897679535367)\n",
      "(('balsamic', 'busses'), 17.186897679535367)\n",
      "(('beach-waves', 'combing'), 17.186897679535367)\n",
      "(('beaver', 'pats'), 17.186897679535367)\n",
      "(('behaving', 'licentious'), 17.186897679535367)\n",
      "(('bitterest', 'envy.'), 17.186897679535367)\n",
      "(('block', 'swags'), 17.186897679535367)\n",
      "(('bokh', 'horse-herd'), 17.186897679535367)\n",
      "(('brownish', 'woolen'), 17.186897679535367)\n",
      "(('bulging', 'store-house'), 17.186897679535367)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#creating a function for non-alphabetic characters:\n",
    "\n",
    "def alpha_filter(w):\n",
    "    pattern = re.compile('^[^a-z]+$') # pattern for non-alphabetical characters\n",
    "    if pattern.match(w):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Applying filter to remove non-alphabetical tokens from bigram    \n",
    "finder2.apply_word_filter(alpha_filter)\n",
    "scored = finder2.score_ngrams(bigram_measures.pmi)\n",
    "\n",
    "for bscore in scored[:20]:\n",
    "    print(bscore) #the values now make more sense\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "51bc5409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n",
      "(('abject', 'louse'), 17.186897679535367)\n",
      "(('abroad', 'swift-rising'), 17.186897679535367)\n",
      "(('accumulating', 'undirected'), 17.186897679535367)\n",
      "(('agnus', 'dei'), 17.186897679535367)\n",
      "(('ague', 'convulse'), 17.186897679535367)\n",
      "(('aimedst', 'highly'), 17.186897679535367)\n",
      "(('alexandrian', 'pharos'), 17.186897679535367)\n",
      "(('ambushes', 'opponents'), 17.186897679535367)\n",
      "(('andirons', 'straddle'), 17.186897679535367)\n",
      "(('artless', 'plaints'), 17.186897679535367)\n",
      "(('au', 'monde'), 17.186897679535367)\n",
      "(('balsamic', 'busses'), 17.186897679535367)\n",
      "(('beach-waves', 'combing'), 17.186897679535367)\n",
      "(('beaver', 'pats'), 17.186897679535367)\n",
      "(('behaving', 'licentious'), 17.186897679535367)\n",
      "(('bitterest', 'envy.'), 17.186897679535367)\n",
      "(('block', 'swags'), 17.186897679535367)\n",
      "(('bokh', 'horse-herd'), 17.186897679535367)\n",
      "(('brownish', 'woolen'), 17.186897679535367)\n",
      "(('bulging', 'store-house'), 17.186897679535367)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Getting stopwords from nltk\n",
    "nltkstopwords = nltk.corpus.stopwords.words('english')\n",
    "print(nltkstopwords[:20])\n",
    "\n",
    "#adding more stopwords to the list\n",
    "morestopwords = ['could','would','might','must','need','sha','wo','y',\"'s\",\"'d\",\"'ll\",\"'t\",\"'m\",\"'re\",\"'ve\", \"n't\"]\n",
    "stopwords = nltkstopwords + morestopwords\n",
    "\n",
    "#Applying filter to remove stopwords\n",
    "\n",
    "finder2.apply_word_filter(alpha_filter)\n",
    "finder2.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder2.score_ngrams(bigram_measures.pmi)\n",
    "\n",
    "for bscore in scored[:20]:\n",
    "    print(bscore) #The bigrams that are generated are more clear now and give a better context about the text.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "889d2efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('walt', 'whitman'), 14.016972678093055)\n",
      "(('shapes', 'arise'), 11.312428561619225)\n",
      "(('thousand', 'miles'), 10.572187835420157)\n",
      "(('became', 'part'), 10.44993208536916)\n",
      "(('thou', 'knowest'), 9.479538547454482)\n",
      "(('due', 'time'), 9.128003990481796)\n",
      "(('white', 'hair'), 8.757042640837946)\n",
      "(('open', 'air'), 8.715939807517042)\n",
      "(('dear', 'son'), 8.653567947229531)\n",
      "(('dear', 'friend'), 8.617042071204416)\n",
      "(('new', 'ones'), 8.586984837348238)\n",
      "(('thousand', 'years'), 8.444083009672472)\n",
      "(('thou', 'hast'), 8.380002873903567)\n",
      "(('none', 'else'), 8.354007665370624)\n",
      "(('comes', 'back'), 8.049586288834465)\n",
      "(('old', 'age'), 8.019479533703628)\n",
      "(('great', 'idea'), 7.990500466731861)\n",
      "(('western', 'sea'), 7.948492940210288)\n",
      "(('little', 'child'), 7.919590779938201)\n",
      "(('many', 'times'), 7.9005049388073)\n"
     ]
    }
   ],
   "source": [
    "finder2.apply_freq_filter(6)\n",
    "scored = finder2.score_ngrams(bigram_measures.pmi)\n",
    "\n",
    "for bscore in scored[:20]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441deab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
