{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48093b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# import wordnet and shorten its name to wn\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9687ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each sense of a word, there is a synset with an id consisting of one of the words,\n",
    "#    whether it is noun, verb, adj or adverb and a number among the synsets of that word\n",
    "# given word \"dog\", returns the ids of the synsets\n",
    "wn.synsets('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da9142ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'domestic_dog', 'Canis_familiaris']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given a synset id, find words/lemma names (the synonyms) of the first noun sense of \"dog\"\n",
    "wn.synset('dog.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0e15233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('dog.n.01.dog'),\n",
       " Lemma('dog.n.01.domestic_dog'),\n",
       " Lemma('dog.n.01.Canis_familiaris')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given a synset id, find lemmas of the synset (a lemma pairs a word with a synset)\n",
    "wn.synset('dog.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb54440d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('dog.n.01')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find synset of a lemma\n",
    "wn.lemma('dog.n.01.domestic_dog').synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bc0f095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01') :   ['dog', 'domestic_dog', 'Canis_familiaris']\n",
      "Synset('frump.n.01') :   ['frump', 'dog']\n",
      "Synset('dog.n.03') :   ['dog']\n",
      "Synset('cad.n.01') :   ['cad', 'bounder', 'blackguard', 'dog', 'hound', 'heel']\n",
      "Synset('frank.n.02') :   ['frank', 'frankfurter', 'hotdog', 'hot_dog', 'dog', 'wiener', 'wienerwurst', 'weenie']\n",
      "Synset('pawl.n.01') :   ['pawl', 'detent', 'click', 'dog']\n",
      "Synset('andiron.n.01') :   ['andiron', 'firedog', 'dog', 'dog-iron']\n",
      "Synset('chase.v.01') :   ['chase', 'chase_after', 'trail', 'tail', 'tag', 'give_chase', 'dog', 'go_after', 'track']\n"
     ]
    }
   ],
   "source": [
    "# find lemma names for all senses of a word\n",
    "for synset in wn.synsets('dog'):\n",
    "    print (synset, \":  \", synset.lemma_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "197c2fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find definition of the first noun sense of dog, or namely, the dog.n.01 synset\n",
    "wn.synset('dog.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92616d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the dog barked all night']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# display an example of the synset\n",
    "wn.synset('dog.n.01').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb9fb3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01') :   a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "Synset('frump.n.01') :   a dull unattractive unpleasant girl or woman\n",
      "Synset('dog.n.03') :   informal term for a man\n",
      "Synset('cad.n.01') :   someone who is morally reprehensible\n",
      "Synset('frank.n.02') :   a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll\n",
      "Synset('pawl.n.01') :   a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward\n",
      "Synset('andiron.n.01') :   metal supports for logs in a fireplace\n",
      "Synset('chase.v.01') :   go after with the intent to catch\n"
     ]
    }
   ],
   "source": [
    "# or show the definitions for all the synsets of a word\n",
    "for synset in wn.synsets('dog'):\n",
    "\tprint (synset, \":  \", synset.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "586559a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01') :  \n",
      "      ['dog', 'domestic_dog', 'Canis_familiaris']\n",
      "      a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "      ['the dog barked all night']\n",
      "Synset('frump.n.01') :  \n",
      "      ['frump', 'dog']\n",
      "      a dull unattractive unpleasant girl or woman\n",
      "      ['she got a reputation as a frump', \"she's a real dog\"]\n",
      "Synset('dog.n.03') :  \n",
      "      ['dog']\n",
      "      informal term for a man\n",
      "      ['you lucky dog']\n",
      "Synset('cad.n.01') :  \n",
      "      ['cad', 'bounder', 'blackguard', 'dog', 'hound', 'heel']\n",
      "      someone who is morally reprehensible\n",
      "      ['you dirty dog']\n",
      "Synset('frank.n.02') :  \n",
      "      ['frank', 'frankfurter', 'hotdog', 'hot_dog', 'dog', 'wiener', 'wienerwurst', 'weenie']\n",
      "      a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll\n",
      "      []\n",
      "Synset('pawl.n.01') :  \n",
      "      ['pawl', 'detent', 'click', 'dog']\n",
      "      a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward\n",
      "      []\n",
      "Synset('andiron.n.01') :  \n",
      "      ['andiron', 'firedog', 'dog', 'dog-iron']\n",
      "      metal supports for logs in a fireplace\n",
      "      ['the andirons were too hot to touch']\n",
      "Synset('chase.v.01') :  \n",
      "      ['chase', 'chase_after', 'trail', 'tail', 'tag', 'give_chase', 'dog', 'go_after', 'track']\n",
      "      go after with the intent to catch\n",
      "      ['The policeman chased the mugger down the alley', 'the dog chased the rabbit']\n"
     ]
    }
   ],
   "source": [
    "# or combine the synonyms/lemma names, definitions and examples\n",
    "for synset in wn.synsets('dog'):\n",
    "\tprint (synset, \":  \")\n",
    "\tprint ('     ', synset.lemma_names())\n",
    "\tprint ('     ', synset.definition())\n",
    "\tprint ('     ', synset.examples())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31a14d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  Lexical relations between synsets in WordNet\n",
    "# find hypernyms of synsets\n",
    "dog1 = wn.synset('dog.n.01')\n",
    "dog1.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "004f4670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('basenji.n.01'),\n",
       " Synset('corgi.n.01'),\n",
       " Synset('cur.n.01'),\n",
       " Synset('dalmatian.n.02'),\n",
       " Synset('great_pyrenees.n.01'),\n",
       " Synset('griffon.n.02'),\n",
       " Synset('hunting_dog.n.01'),\n",
       " Synset('lapdog.n.01'),\n",
       " Synset('leonberg.n.01'),\n",
       " Synset('mexican_hairless.n.01'),\n",
       " Synset('newfoundland.n.01'),\n",
       " Synset('pooch.n.01'),\n",
       " Synset('poodle.n.01'),\n",
       " Synset('pug.n.01'),\n",
       " Synset('puppy.n.01'),\n",
       " Synset('spitz.n.01'),\n",
       " Synset('toy_dog.n.01'),\n",
       " Synset('working_dog.n.01')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find hyponyms\n",
    "dog1.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8d03bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the most general hypernym of a synset\n",
    "dog1.root_hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ef4bfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('flag.n.07')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from the wordnet browser, we see that dog1 has two more relations\n",
    "dog1.part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb42d8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flag'] a conspicuously marked or shaped tail []\n"
     ]
    }
   ],
   "source": [
    "# what is this?  check it out \n",
    "print (wn.synset('flag.n.07').lemma_names(),wn.synset('flag.n.07').definition(), \n",
    "       wn.synset('flag.n.07').examples())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f200542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canis.n.01'), Synset('pack.n.06')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the other relation for dog1\n",
    "dog1.member_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "770be486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('good.n.01'),\n",
       " Synset('good.n.02'),\n",
       " Synset('good.n.03'),\n",
       " Synset('commodity.n.01'),\n",
       " Synset('good.a.01'),\n",
       " Synset('full.s.06'),\n",
       " Synset('good.a.03'),\n",
       " Synset('estimable.s.02'),\n",
       " Synset('beneficial.s.01'),\n",
       " Synset('good.s.06'),\n",
       " Synset('good.s.07'),\n",
       " Synset('adept.s.01'),\n",
       " Synset('good.s.09'),\n",
       " Synset('dear.s.02'),\n",
       " Synset('dependable.s.04'),\n",
       " Synset('good.s.12'),\n",
       " Synset('good.s.13'),\n",
       " Synset('effective.s.04'),\n",
       " Synset('good.s.15'),\n",
       " Synset('good.s.16'),\n",
       " Synset('good.s.17'),\n",
       " Synset('good.s.18'),\n",
       " Synset('good.s.19'),\n",
       " Synset('good.s.20'),\n",
       " Synset('good.s.21'),\n",
       " Synset('well.r.01'),\n",
       " Synset('thoroughly.r.02')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at another word, the adjective \"good\"\n",
    "wn.synsets('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fad4223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find antonyms, sometimes need to specify for which lemma the antonym is needed\n",
    "good1 = wn.synset('good.a.01')\n",
    "# display synonyms of this synset\n",
    "good1.lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6cf4ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('good.a.01.good')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Lemma('bad.a.01.bad')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the antonym function is defined only on the lemma, not the synset\n",
    "# find antonym for the first lemma of the synset\n",
    "print(good1.lemmas())\n",
    "good1.lemmas()[0].antonyms() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1759a041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('step.v.01')]\n",
      "[Synset('chew.v.01'), Synset('swallow.v.01')]\n"
     ]
    }
   ],
   "source": [
    "# find entailments of verbs\n",
    "print(wn.synset('walk.v.01').entailments())\n",
    "print(wn.synset('eat.v.01').entailments())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ac4a7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trace paths of a synset by visiting its hypernyms\n",
    "dog1.hypernyms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51355586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('object.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('living_thing.n.01'),\n",
       " Synset('organism.n.01'),\n",
       " Synset('animal.n.01'),\n",
       " Synset('chordate.n.01'),\n",
       " Synset('vertebrate.n.01'),\n",
       " Synset('mammal.n.01'),\n",
       " Synset('placental.n.01'),\n",
       " Synset('carnivore.n.01'),\n",
       " Synset('canine.n.02'),\n",
       " Synset('dog.n.01')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of paths from the synset to the root concept \"entity\"\n",
    "paths=dog1.hypernym_paths()\n",
    "print(len(paths) )\n",
    "# look at the first path\n",
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2ee85c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'living_thing.n.01',\n",
       " 'organism.n.01',\n",
       " 'animal.n.01',\n",
       " 'chordate.n.01',\n",
       " 'vertebrate.n.01',\n",
       " 'mammal.n.01',\n",
       " 'placental.n.01',\n",
       " 'carnivore.n.01',\n",
       " 'canine.n.02',\n",
       " 'dog.n.01']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or just list the names in the paths\n",
    "#list the first path\n",
    "[synset.name() for synset in paths[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfb301ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'living_thing.n.01',\n",
       " 'organism.n.01',\n",
       " 'animal.n.01',\n",
       " 'domestic_animal.n.01',\n",
       " 'dog.n.01']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list the second path \n",
    "[synset.name() for synset in paths[1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ee3b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Word similarity\n",
    "\n",
    "# define 3 different types of whales\n",
    "right = wn.synset('right_whale.n.01')\n",
    "minke = wn.synset('minke_whale.n.01')  \n",
    "orca = wn.synset('orca.n.01') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "caa96875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('aquatic_mammal.n.01'), Synset('cetacean.n.01'), Synset('whale.n.02'), Synset('baleen_whale.n.01'), Synset('right_whale.n.01')]]\n",
      "[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('aquatic_mammal.n.01'), Synset('cetacean.n.01'), Synset('whale.n.02'), Synset('baleen_whale.n.01'), Synset('rorqual.n.01'), Synset('lesser_rorqual.n.01')]]\n",
      "[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('aquatic_mammal.n.01'), Synset('cetacean.n.01'), Synset('whale.n.02'), Synset('toothed_whale.n.01'), Synset('dolphin.n.02'), Synset('killer_whale.n.01')]]\n"
     ]
    }
   ],
   "source": [
    "# look at the paths of these three whales\n",
    "print(right.hypernym_paths())\n",
    "print(minke.hypernym_paths())\n",
    "print(orca.hypernym_paths())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d51c702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('baleen_whale.n.01')]\n",
      "[Synset('whale.n.02')]\n"
     ]
    }
   ],
   "source": [
    "# find the least ancestor of right and minke, and then right and orca\n",
    "print(right.lowest_common_hypernyms(minke))\n",
    "print(right.lowest_common_hypernyms(orca))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6087411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "14\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# the function min_depth gives the length of a path from a word to the top of the hierarchy\n",
    "print(right.min_depth() )\n",
    "print(wn.synset('baleen_whale.n.01').min_depth() )\n",
    "print(wn.synset('entity.n.01').min_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8aafdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# the path similarity gives a similarity score between 0 and 1\n",
    "print(right.path_similarity(minke) )\n",
    "print(right.path_similarity(orca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "834c75e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('vertebrate.n.01')]\n",
      "[Synset('entity.n.01')]\n"
     ]
    }
   ],
   "source": [
    "# define 2 more words and look at their similarity\n",
    "tortoise = wn.synset('tortoise.n.01')\n",
    "novel = wn.synset('novel.n.01')\n",
    "# note the least ancestor of these two words\n",
    "print(right.lowest_common_hypernyms(tortoise))\n",
    "print(right.lowest_common_hypernyms(novel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c262bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07692307692307693\n",
      "0.043478260869565216\n"
     ]
    }
   ],
   "source": [
    "print(right.path_similarity(tortoise) )\n",
    "print(right.path_similarity(novel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c0b13b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on WordNetCorpusReader in module nltk.corpus.reader.wordnet object:\n",
      "\n",
      "class WordNetCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      " |  WordNetCorpusReader(root, omw_reader)\n",
      " |  \n",
      " |  A corpus reader used to access wordnet or its variants.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      WordNetCorpusReader\n",
      " |      nltk.corpus.reader.api.CorpusReader\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, root, omw_reader)\n",
      " |      Construct a new wordnet corpus reader, with the given root\n",
      " |      directory.\n",
      " |  \n",
      " |  all_eng_synsets(self, pos=None)\n",
      " |  \n",
      " |  all_lemma_names(self, pos=None, lang='eng')\n",
      " |      Return all lemma names for all synsets for the given\n",
      " |      part of speech tag and language or languages. If pos is\n",
      " |      not specified, all synsets for all parts of speech will\n",
      " |      be used.\n",
      " |  \n",
      " |  all_omw_synsets(self, pos=None, lang=None)\n",
      " |  \n",
      " |  all_synsets(self, pos=None, lang='eng')\n",
      " |      Iterate over all synsets with a given part of speech tag.\n",
      " |      If no pos is specified, all synsets for all parts of speech\n",
      " |      will be loaded.\n",
      " |  \n",
      " |  citation(self, lang='eng')\n",
      " |      Return the contents of citation.bib file (for omw)\n",
      " |      use lang=lang to get the citation for an individual language\n",
      " |  \n",
      " |  corpus2sk(self, corpus=None)\n",
      " |      Read sense key to synset id mapping,\n",
      " |      from index.sense file in corpus directory\n",
      " |  \n",
      " |  custom_lemmas(self, tab_file, lang)\n",
      " |      Reads a custom tab file containing mappings of lemmas in the given\n",
      " |      language to Princeton WordNet 3.0 synset offsets, allowing NLTK's\n",
      " |      WordNet functions to then be used with that language.\n",
      " |      \n",
      " |      See the \"Tab files\" section at http://compling.hss.ntu.edu.sg/omw/ for\n",
      " |      documentation on the Multilingual WordNet tab file format.\n",
      " |      \n",
      " |      :param tab_file: Tab file as a file or file-like object\n",
      " |      :type: lang str\n",
      " |      :param: lang ISO 639-3 code of the language of the tab file\n",
      " |  \n",
      " |  digraph(self, inputs, rel=<function WordNetCorpusReader.<lambda> at 0x00000162A3599CA0>, pos=None, maxdepth=-1, shapes=None, attr=None, verbose=False)\n",
      " |      Produce a graphical representation from 'inputs' (a list of\n",
      " |      start nodes, which can be a mix of Synsets, Lemmas and/or words),\n",
      " |      and a synset relation, for drawing with the 'dot' graph visualisation\n",
      " |      program from the Graphviz package.\n",
      " |      \n",
      " |      Return a string in the DOT graph file language, which can then be\n",
      " |      converted to an image by nltk.parse.dependencygraph.dot2img(dot_string).\n",
      " |      \n",
      " |      Optional Parameters:\n",
      " |      :rel: Wordnet synset relation\n",
      " |      :pos: for words, restricts Part of Speech to 'n', 'v', 'a' or 'r'\n",
      " |      :maxdepth: limit the longest path\n",
      " |      :shapes: dictionary of strings that trigger a specified shape\n",
      " |      :attr: dictionary with global graph attributes\n",
      " |      :verbose: warn about cycles\n",
      " |      \n",
      " |      >>> from nltk.corpus import wordnet as wn\n",
      " |      >>> print(wn.digraph([wn.synset('dog.n.01')]))\n",
      " |      digraph G {\n",
      " |      \"Synset('dog.n.01')\" -> \"Synset('domestic_animal.n.01')\";\n",
      " |      \"Synset('organism.n.01')\" -> \"Synset('living_thing.n.01')\";\n",
      " |      \"Synset('mammal.n.01')\" -> \"Synset('vertebrate.n.01')\";\n",
      " |      \"Synset('placental.n.01')\" -> \"Synset('mammal.n.01')\";\n",
      " |      \"Synset('animal.n.01')\" -> \"Synset('organism.n.01')\";\n",
      " |      \"Synset('vertebrate.n.01')\" -> \"Synset('chordate.n.01')\";\n",
      " |      \"Synset('chordate.n.01')\" -> \"Synset('animal.n.01')\";\n",
      " |      \"Synset('canine.n.02')\" -> \"Synset('carnivore.n.01')\";\n",
      " |      \"Synset('living_thing.n.01')\" -> \"Synset('whole.n.02')\";\n",
      " |      \"Synset('physical_entity.n.01')\" -> \"Synset('entity.n.01')\";\n",
      " |      \"Synset('carnivore.n.01')\" -> \"Synset('placental.n.01')\";\n",
      " |      \"Synset('object.n.01')\" -> \"Synset('physical_entity.n.01')\";\n",
      " |      \"Synset('whole.n.02')\" -> \"Synset('object.n.01')\";\n",
      " |      \"Synset('dog.n.01')\" -> \"Synset('canine.n.02')\";\n",
      " |      \"Synset('domestic_animal.n.01')\" -> \"Synset('animal.n.01')\";\n",
      " |      }\n",
      " |  \n",
      " |  doc(self, file='README', lang='eng')\n",
      " |      Return the contents of readme, license or citation file\n",
      " |      use lang=lang to get the file for an individual language\n",
      " |  \n",
      " |  get_version(self)\n",
      " |  \n",
      " |  ic(self, corpus, weight_senses_equally=False, smoothing=1.0)\n",
      " |      Creates an information content lookup dictionary from a corpus.\n",
      " |      \n",
      " |      :type corpus: CorpusReader\n",
      " |      :param corpus: The corpus from which we create an information\n",
      " |          content dictionary.\n",
      " |      :type weight_senses_equally: bool\n",
      " |      :param weight_senses_equally: If this is True, gives all\n",
      " |          possible senses equal weight rather than dividing by the\n",
      " |          number of possible senses.  (If a word has 3 synses, each\n",
      " |          sense gets 0.3333 per appearance when this is False, 1.0 when\n",
      " |          it is true.)\n",
      " |      :param smoothing: How much do we smooth synset counts (default is 1.0)\n",
      " |      :type smoothing: float\n",
      " |      :return: An information content dictionary\n",
      " |  \n",
      " |  jcn_similarity(self, synset1, synset2, ic, verbose=False)\n",
      " |      Jiang-Conrath Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      " |      ancestor node) and that of the two input Synsets. The relationship is\n",
      " |      given by the equation 1 / (IC(s1) + IC(s2) - 2 * IC(lcs)).\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type  ic: dict\n",
      " |      :param ic: an information content object (as returned by\n",
      " |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects.\n",
      " |  \n",
      " |  langs(self)\n",
      " |      return a list of languages supported by Multilingual Wordnet\n",
      " |  \n",
      " |  lch_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      " |      Leacock Chodorow Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      shortest path that connects the senses (as above) and the maximum depth\n",
      " |      of the taxonomy in which the senses occur. The relationship is given as\n",
      " |      -log(p/2d) where p is the shortest path length and d is the taxonomy\n",
      " |      depth.\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type simulate_root: bool\n",
      " |      :param simulate_root: The various verb taxonomies do not\n",
      " |          share a single root which disallows this metric from working for\n",
      " |          synsets that are not connected. This flag (True by default)\n",
      " |          creates a fake root that connects all the taxonomies. Set it\n",
      " |          to false to disable this behavior. For the noun taxonomy,\n",
      " |          there is usually a default root except for WordNet version 1.6.\n",
      " |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      " |          as well.\n",
      " |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      " |          normally greater than 0. None is returned if no connecting path\n",
      " |          could be found. If a ``Synset`` is compared with itself, the\n",
      " |          maximum score is returned, which varies depending on the taxonomy\n",
      " |          depth.\n",
      " |  \n",
      " |  lemma(self, name, lang='eng')\n",
      " |      Return lemma object that matches the name\n",
      " |  \n",
      " |  lemma_count(self, lemma)\n",
      " |      Return the frequency count for this Lemma\n",
      " |  \n",
      " |  lemma_from_key(self, key)\n",
      " |  \n",
      " |  lemmas(self, lemma, pos=None, lang='eng')\n",
      " |      Return all Lemma objects with a name matching the specified lemma\n",
      " |      name and part of speech tag. Matches any part of speech tag if none is\n",
      " |      specified.\n",
      " |  \n",
      " |  license(self, lang='eng')\n",
      " |      Return the contents of LICENSE (for omw)\n",
      " |      use lang=lang to get the license for an individual language\n",
      " |  \n",
      " |  lin_similarity(self, synset1, synset2, ic, verbose=False)\n",
      " |      Lin Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      " |      ancestor node) and that of the two input Synsets. The relationship is\n",
      " |      given by the equation 2 * IC(lcs) / (IC(s1) + IC(s2)).\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type ic: dict\n",
      " |      :param ic: an information content object (as returned by\n",
      " |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects, in the range 0 to 1.\n",
      " |  \n",
      " |  map_wn30(self)\n",
      " |      Mapping from Wordnet 3.0 to currently loaded Wordnet version\n",
      " |  \n",
      " |  morphy(self, form, pos=None, check_exceptions=True)\n",
      " |      Find a possible base form for the given form, with the given\n",
      " |      part of speech, by checking WordNet's list of exceptional\n",
      " |      forms, and by recursively stripping affixes for this part of\n",
      " |      speech until a form in WordNet is found.\n",
      " |      \n",
      " |      >>> from nltk.corpus import wordnet as wn\n",
      " |      >>> print(wn.morphy('dogs'))\n",
      " |      dog\n",
      " |      >>> print(wn.morphy('churches'))\n",
      " |      church\n",
      " |      >>> print(wn.morphy('aardwolves'))\n",
      " |      aardwolf\n",
      " |      >>> print(wn.morphy('abaci'))\n",
      " |      abacus\n",
      " |      >>> wn.morphy('hardrock', wn.ADV)\n",
      " |      >>> print(wn.morphy('book', wn.NOUN))\n",
      " |      book\n",
      " |      >>> wn.morphy('book', wn.ADJ)\n",
      " |  \n",
      " |  of2ss(self, of)\n",
      " |      take an id and return the synsets\n",
      " |  \n",
      " |  omw_prov(self)\n",
      " |      Return a provenance dictionary of the languages in  Multilingual Wordnet\n",
      " |  \n",
      " |  path_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      " |      Path Distance Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      shortest path that connects the senses in the is-a (hypernym/hypnoym)\n",
      " |      taxonomy. The score is in the range 0 to 1, except in those cases where\n",
      " |      a path cannot be found (will only be true for verbs as there are many\n",
      " |      distinct verb taxonomies), in which case None is returned. A score of\n",
      " |      1 represents identity i.e. comparing a sense with itself will return 1.\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type simulate_root: bool\n",
      " |      :param simulate_root: The various verb taxonomies do not\n",
      " |          share a single root which disallows this metric from working for\n",
      " |          synsets that are not connected. This flag (True by default)\n",
      " |          creates a fake root that connects all the taxonomies. Set it\n",
      " |          to false to disable this behavior. For the noun taxonomy,\n",
      " |          there is usually a default root except for WordNet version 1.6.\n",
      " |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      " |          as well.\n",
      " |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      " |          normally between 0 and 1. None is returned if no connecting path\n",
      " |          could be found. 1 is returned if a ``Synset`` is compared with\n",
      " |          itself.\n",
      " |  \n",
      " |  readme(self, lang='eng')\n",
      " |      Return the contents of README (for omw)\n",
      " |      use lang=lang to get the readme for an individual language\n",
      " |  \n",
      " |  res_similarity(self, synset1, synset2, ic, verbose=False)\n",
      " |      Resnik Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      " |      ancestor node).\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type ic: dict\n",
      " |      :param ic: an information content object (as returned by\n",
      " |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects. Synsets whose LCS is the root node of the taxonomy will\n",
      " |          have a score of 0 (e.g. N['dog'][0] and N['table'][0]).\n",
      " |  \n",
      " |  ss2of(self, ss, lang=None)\n",
      " |      return the ID of the synset\n",
      " |  \n",
      " |  synset(self, name)\n",
      " |      #############################################################\n",
      " |      # Loading Synsets\n",
      " |      #############################################################\n",
      " |  \n",
      " |  synset_from_pos_and_offset(self, pos, offset)\n",
      " |      - pos: The synset's part of speech, matching one of the module level\n",
      " |        attributes ADJ, ADJ_SAT, ADV, NOUN or VERB ('a', 's', 'r', 'n', or 'v').\n",
      " |      - offset: The byte offset of this synset in the WordNet dict file\n",
      " |        for this pos.\n",
      " |      \n",
      " |      >>> from nltk.corpus import wordnet as wn\n",
      " |      >>> print(wn.synset_from_pos_and_offset('n', 1740))\n",
      " |      Synset('entity.n.01')\n",
      " |  \n",
      " |  synset_from_sense_key(self, sense_key)\n",
      " |      Retrieves synset based on a given sense_key. Sense keys can be\n",
      " |      obtained from lemma.key()\n",
      " |      \n",
      " |      From https://wordnet.princeton.edu/documentation/senseidx5wn:\n",
      " |      A sense_key is represented as::\n",
      " |      \n",
      " |          lemma % lex_sense (e.g. 'dog%1:18:01::')\n",
      " |      \n",
      " |      where lex_sense is encoded as::\n",
      " |      \n",
      " |          ss_type:lex_filenum:lex_id:head_word:head_id\n",
      " |      \n",
      " |      :lemma:       ASCII text of word/collocation, in lower case\n",
      " |      :ss_type:     synset type for the sense (1 digit int)\n",
      " |                    The synset type is encoded as follows::\n",
      " |      \n",
      " |                        1    NOUN\n",
      " |                        2    VERB\n",
      " |                        3    ADJECTIVE\n",
      " |                        4    ADVERB\n",
      " |                        5    ADJECTIVE SATELLITE\n",
      " |      :lex_filenum: name of lexicographer file containing the synset for the sense (2 digit int)\n",
      " |      :lex_id:      when paired with lemma, uniquely identifies a sense in the lexicographer file (2 digit int)\n",
      " |      :head_word:   lemma of the first word in satellite's head synset\n",
      " |                    Only used if sense is in an adjective satellite synset\n",
      " |      :head_id:     uniquely identifies sense in a lexicographer file when paired with head_word\n",
      " |                    Only used if head_word is present (2 digit int)\n",
      " |      \n",
      " |      >>> import nltk\n",
      " |      >>> from nltk.corpus import wordnet as wn\n",
      " |      >>> print(wn.synset_from_sense_key(\"drive%1:04:03::\"))\n",
      " |      Synset('drive.n.06')\n",
      " |      \n",
      " |      >>> print(wn.synset_from_sense_key(\"driving%1:04:03::\"))\n",
      " |      Synset('drive.n.06')\n",
      " |  \n",
      " |  synsets(self, lemma, pos=None, lang='eng', check_exceptions=True)\n",
      " |      Load all synsets with a given lemma and part of speech tag.\n",
      " |      If no pos is specified, all synsets for all parts of speech\n",
      " |      will be loaded.\n",
      " |      If lang is specified, all the synsets associated with the lemma name\n",
      " |      of that language will be returned.\n",
      " |  \n",
      " |  words(self, lang='eng')\n",
      " |      return lemmas of the given language as list of words\n",
      " |  \n",
      " |  wup_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      " |      Wu-Palmer Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      depth of the two senses in the taxonomy and that of their Least Common\n",
      " |      Subsumer (most specific ancestor node). Previously, the scores computed\n",
      " |      by this implementation did _not_ always agree with those given by\n",
      " |      Pedersen's Perl implementation of WordNet Similarity. However, with\n",
      " |      the addition of the simulate_root flag (see below), the score for\n",
      " |      verbs now almost always agree but not always for nouns.\n",
      " |      \n",
      " |      The LCS does not necessarily feature in the shortest path connecting\n",
      " |      the two senses, as it is by definition the common ancestor deepest in\n",
      " |      the taxonomy, not closest to the two senses. Typically, however, it\n",
      " |      will so feature. Where multiple candidates for the LCS exist, that\n",
      " |      whose shortest path to the root node is the longest will be selected.\n",
      " |      Where the LCS has multiple paths to the root, the longer path is used\n",
      " |      for the purposes of the calculation.\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type simulate_root: bool\n",
      " |      :param simulate_root: The various verb taxonomies do not\n",
      " |          share a single root which disallows this metric from working for\n",
      " |          synsets that are not connected. This flag (True by default)\n",
      " |          creates a fake root that connects all the taxonomies. Set it\n",
      " |          to false to disable this behavior. For the noun taxonomy,\n",
      " |          there is usually a default root except for WordNet version 1.6.\n",
      " |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      " |          as well.\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects, normally greater than zero. If no connecting path between\n",
      " |          the two senses can be found, None is returned.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  ADJ = 'a'\n",
      " |  \n",
      " |  ADJ_SAT = 's'\n",
      " |  \n",
      " |  ADV = 'r'\n",
      " |  \n",
      " |  MORPHOLOGICAL_SUBSTITUTIONS = {'a': [('er', ''), ('est', ''), ('er', '...\n",
      " |  \n",
      " |  NOUN = 'n'\n",
      " |  \n",
      " |  VERB = 'v'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  abspath(self, fileid)\n",
      " |      Return the absolute path for the given file.\n",
      " |      \n",
      " |      :type fileid: str\n",
      " |      :param fileid: The file identifier for the file whose path\n",
      " |          should be returned.\n",
      " |      :rtype: PathPointer\n",
      " |  \n",
      " |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      " |      Return a list of the absolute paths for all fileids in this corpus;\n",
      " |      or for the given list of fileids, if specified.\n",
      " |      \n",
      " |      :type fileids: None or str or list\n",
      " |      :param fileids: Specifies the set of fileids for which paths should\n",
      " |          be returned.  Can be None, for all fileids; a list of\n",
      " |          file identifiers, for a specified set of fileids; or a single\n",
      " |          file identifier, for a single file.  Note that the return\n",
      " |          value is always a list of paths, even if ``fileids`` is a\n",
      " |          single file identifier.\n",
      " |      \n",
      " |      :param include_encoding: If true, then return a list of\n",
      " |          ``(path_pointer, encoding)`` tuples.\n",
      " |      \n",
      " |      :rtype: list(PathPointer)\n",
      " |  \n",
      " |  encoding(self, file)\n",
      " |      Return the unicode encoding for the given corpus file, if known.\n",
      " |      If the encoding is unknown, or if the given file should be\n",
      " |      processed using byte strings (str), then return None.\n",
      " |  \n",
      " |  ensure_loaded(self)\n",
      " |      Load this corpus (if it has not already been loaded).  This is\n",
      " |      used by LazyCorpusLoader as a simple method that can be used to\n",
      " |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      " |      do help(some_corpus).\n",
      " |  \n",
      " |  fileids(self)\n",
      " |      Return a list of file identifiers for the fileids that make up\n",
      " |      this corpus.\n",
      " |  \n",
      " |  open(self, file)\n",
      " |      Return an open stream that can be used to read the given file.\n",
      " |      If the file's encoding is not None, then the stream will\n",
      " |      automatically decode the file's contents into unicode.\n",
      " |      \n",
      " |      :param file: The file identifier of the file to read.\n",
      " |  \n",
      " |  raw(self, fileids=None)\n",
      " |      :param fileids: A list specifying the fileids that should be used.\n",
      " |      :return: the given file(s) as a single string.\n",
      " |      :rtype: str\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from nltk.corpus.reader.api.CorpusReader:\n",
      " |  \n",
      " |  root\n",
      " |      The directory where this corpus is stored.\n",
      " |      \n",
      " |      :type: PathPointer\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# other similarity measures\n",
    "help(wn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aba07b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.845826690498331\n",
      "1.072636802264849\n",
      "0.5020919437972361\n"
     ]
    }
   ],
   "source": [
    "# Leacock-Chodorow Similarity, also uses path lengths and others\n",
    "print(right.lch_similarity(orca))\n",
    "print(right.lch_similarity(tortoise))\n",
    "print(right.lch_similarity(novel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "910f94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnick similarity gets information content measure\n",
    "# first get information content from a general corpus\n",
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c113ee9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.939239388446227\n",
      "5.2175784741185165\n",
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "# try Resnik Similarity\n",
    "print(right.res_similarity(orca, brown_ic))\n",
    "print(right.res_similarity(tortoise, brown_ic))\n",
    "print(right.res_similarity(novel, brown_ic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f52e05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SentiWordNet\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "# each word judged to be made up of positive, negative and objective meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dc59a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SentiSynset('dislocation.n.02'), SentiSynset('breakdown.n.02'), SentiSynset('breakdown.n.03'), SentiSynset('breakdown.n.04')]\n",
      "[Synset('dislocation.n.02'), Synset('breakdown.n.02'), Synset('breakdown.n.03'), Synset('breakdown.n.04')]\n"
     ]
    }
   ],
   "source": [
    "# sentiwordnet has the same synsets as wordnet, use wn functions\n",
    "print(list(swn.senti_synsets('breakdown')))\n",
    "print(wn.synsets('breakdown'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5addc02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<breakdown.n.03: PosScore=0.0 NegScore=0.25>\n"
     ]
    }
   ],
   "source": [
    "# the print function gives the positive and negative scores\n",
    "breakdown3 = swn.senti_synset('breakdown.n.03')\n",
    "print (breakdown3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9c7d50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.25\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# there are also separate functions for all the scores\n",
    "print(breakdown3.pos_score())\n",
    "print(breakdown3.neg_score())\n",
    "print(breakdown3.obj_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec169f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dog.n.01: PosScore=0.0 NegScore=0.0>\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# some more exploration of sentiment scores of words\n",
    "dogswn1 = swn.senti_synset('dog.n.01')\n",
    "print(dogswn1)\n",
    "print(dogswn1.obj_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25c3181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<good.a.01: PosScore=0.75 NegScore=0.0>\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "goodswn1 = swn.senti_synset('good.a.01')\n",
    "print(goodswn1)\n",
    "print(goodswn1.obj_score())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ccf5304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('ebullient.s.01'), Synset('excessive.s.02'), Synset('exuberant.s.03')]\n",
      "<exuberant.s.03: PosScore=0.0 NegScore=0.25>\n"
     ]
    }
   ],
   "source": [
    "# not all words in WordNet have been scored for sentiment in SentiWordNet\n",
    "#   but the most recent version has scored a lot more so I don't have an example right now\n",
    "print(wn.synsets('exuberant'))\n",
    "ex3 = swn.senti_synset('exuberant.s.03')\n",
    "print(ex3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239b849",
   "metadata": {},
   "source": [
    "LAB6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6dca8939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('hit.n.01'),\n",
       " Synset('hit.n.02'),\n",
       " Synset('hit.n.03'),\n",
       " Synset('collision.n.01'),\n",
       " Synset('hit.n.05'),\n",
       " Synset('hit.n.06'),\n",
       " Synset('hit.n.07'),\n",
       " Synset('hit.v.01'),\n",
       " Synset('hit.v.02'),\n",
       " Synset('hit.v.03'),\n",
       " Synset('reach.v.01'),\n",
       " Synset('hit.v.05'),\n",
       " Synset('shoot.v.01'),\n",
       " Synset('stumble.v.03'),\n",
       " Synset('score.v.01'),\n",
       " Synset('hit.v.09'),\n",
       " Synset('strike.v.04'),\n",
       " Synset('murder.v.01'),\n",
       " Synset('hit.v.12'),\n",
       " Synset('reach.v.02'),\n",
       " Synset('strike.v.10'),\n",
       " Synset('hit.v.15'),\n",
       " Synset('hit.v.16'),\n",
       " Synset('hit.v.17')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a word\n",
    "\n",
    "hit = wn.synsets(\"hit\")\n",
    "hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3f1f3079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('hit.n.01') :  ['hit']\n",
      "Synset('hit.n.02') :  ['hit', 'hitting', 'striking']\n",
      "Synset('hit.n.03') :  ['hit', 'smash', 'smasher', 'strike', 'bang']\n",
      "Synset('collision.n.01') :  ['collision', 'hit']\n",
      "Synset('hit.n.05') :  ['hit']\n",
      "Synset('hit.n.06') :  ['hit']\n",
      "Synset('hit.n.07') :  ['hit']\n",
      "Synset('hit.v.01') :  ['hit']\n",
      "Synset('hit.v.02') :  ['hit', 'strike', 'impinge_on', 'run_into', 'collide_with']\n",
      "Synset('hit.v.03') :  ['hit']\n",
      "Synset('reach.v.01') :  ['reach', 'make', 'attain', 'hit', 'arrive_at', 'gain']\n",
      "Synset('hit.v.05') :  ['hit', 'strike']\n",
      "Synset('shoot.v.01') :  ['shoot', 'hit', 'pip']\n",
      "Synset('stumble.v.03') :  ['stumble', 'hit']\n",
      "Synset('score.v.01') :  ['score', 'hit', 'tally', 'rack_up']\n",
      "Synset('hit.v.09') :  ['hit', 'strike', 'come_to']\n",
      "Synset('strike.v.04') :  ['strike', 'hit']\n",
      "Synset('murder.v.01') :  ['murder', 'slay', 'hit', 'dispatch', 'bump_off', 'off', 'polish_off', 'remove']\n",
      "Synset('hit.v.12') :  ['hit', 'strike']\n",
      "Synset('reach.v.02') :  ['reach', 'hit', 'attain']\n",
      "Synset('strike.v.10') :  ['strike', 'hit']\n",
      "Synset('hit.v.15') :  ['hit']\n",
      "Synset('hit.v.16') :  ['hit']\n",
      "Synset('hit.v.17') :  ['hit']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hit)): \n",
    "    print(hit[i], ': ', hit[i].lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bdb8b3a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('hit.n.01') :  (baseball) a successful stroke in an athletic contest (especially in baseball)\n",
      "Synset('hit.n.02') :  the act of contacting one thing with another\n",
      "Synset('hit.n.03') :  a conspicuous success\n",
      "Synset('collision.n.01') :  (physics) a brief event in which two or more bodies come together\n",
      "Synset('hit.n.05') :  a dose of a narcotic drug\n",
      "Synset('hit.n.06') :  a murder carried out by an underworld syndicate\n",
      "Synset('hit.n.07') :  a connection made via the internet to another website\n",
      "Synset('hit.v.01') :  cause to move by striking\n",
      "Synset('hit.v.02') :  hit against; come into sudden contact with\n",
      "Synset('hit.v.03') :  deal a blow to, either with the hand or with an instrument\n",
      "Synset('reach.v.01') :  reach a destination, either real or abstract\n",
      "Synset('hit.v.05') :  affect or afflict suddenly, usually adversely\n",
      "Synset('shoot.v.01') :  hit with a missile from a weapon\n",
      "Synset('stumble.v.03') :  encounter by chance\n",
      "Synset('score.v.01') :  gain points in a game\n",
      "Synset('hit.v.09') :  cause to experience suddenly\n",
      "Synset('strike.v.04') :  make a strategic, offensive, assault against an enemy, opponent, or a target\n",
      "Synset('murder.v.01') :  kill intentionally and with premeditation\n",
      "Synset('hit.v.12') :  drive something violently into a location\n",
      "Synset('reach.v.02') :  reach a point in time, or a certain state or level\n",
      "Synset('strike.v.10') :  produce by manipulating keys or strings of musical instruments, also metaphorically\n",
      "Synset('hit.v.15') :  consume to excess\n",
      "Synset('hit.v.16') :  hit the intended target or goal\n",
      "Synset('hit.v.17') :  pay unsolicited and usually unwanted sexual attention to\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hit)): \n",
    "    print(hit[i], ': ', hit[i].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "00f93e1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('hit.n.01') :  [\"he came all the way around on Williams' hit\"]\n",
      "Synset('hit.n.02') :  ['repeated hitting raised a large bruise', 'after three misses she finally got a hit']\n",
      "Synset('hit.n.03') :  ['that song was his first hit and marked the beginning of his career', 'that new Broadway show is a real smasher', 'the party went with a bang']\n",
      "Synset('collision.n.01') :  ['the collision of the particles resulted in an exchange of energy and a change of direction']\n",
      "Synset('hit.n.05') :  []\n",
      "Synset('hit.n.06') :  ['it has all the earmarks of a Mafia hit']\n",
      "Synset('hit.n.07') :  ['WordNet gets many hits from users worldwide']\n",
      "Synset('hit.v.01') :  ['hit a ball']\n",
      "Synset('hit.v.02') :  ['The car hit a tree', 'He struck the table with his elbow']\n",
      "Synset('hit.v.03') :  ['He hit her hard in the face']\n",
      "Synset('reach.v.01') :  ['We hit Detroit by noon', 'The water reached the doorstep', 'We barely made it to the finish line', 'I have to hit the MAC machine before the weekend starts']\n",
      "Synset('hit.v.05') :  ['We were hit by really bad weather', 'He was stricken with cancer when he was still a teenager', 'The earthquake struck at midnight']\n",
      "Synset('shoot.v.01') :  []\n",
      "Synset('stumble.v.03') :  ['I stumbled across a long-lost cousin last night in a restaurant']\n",
      "Synset('score.v.01') :  ['The home team scored many times', 'He hit a home run', 'He hit .300 in the past season']\n",
      "Synset('hit.v.09') :  ['Panic struck me', 'An interesting idea hit her', 'A thought came to me', 'The thought struck terror in our minds', 'They were struck with fear']\n",
      "Synset('strike.v.04') :  ['The Germans struck Poland on Sept. 1, 1939', \"We must strike the enemy's oil fields\", 'in the fifth inning, the Giants struck, sending three runners home to win the game 5 to 2']\n",
      "Synset('murder.v.01') :  ['The mafia boss ordered his enemies murdered']\n",
      "Synset('hit.v.12') :  ['he hit his fist on the table', 'she struck her head on the low ceiling']\n",
      "Synset('reach.v.02') :  ['The thermometer hit 100 degrees', 'This car can reach a speed of 140 miles per hour']\n",
      "Synset('strike.v.10') :  ['The pianist strikes a middle C', \"strike `z' on the keyboard\", 'her comments struck a sour note']\n",
      "Synset('hit.v.15') :  ['hit the bottle']\n",
      "Synset('hit.v.16') :  []\n",
      "Synset('hit.v.17') :  ['He tries to hit on women in bars']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hit)): \n",
    "    print(hit[i], ': ', hit[i].examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b9046262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('touch.n.05')]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit[1].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "07dc1119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('kill.v.01')]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit[17].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dbc74860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('entity.n.01'),\n",
       "  Synset('abstraction.n.06'),\n",
       "  Synset('psychological_feature.n.01'),\n",
       "  Synset('event.n.01'),\n",
       "  Synset('act.n.02'),\n",
       "  Synset('touch.n.05'),\n",
       "  Synset('hit.n.02')]]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit[1].hypernym_paths() #chair.n.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "50ceb784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('kill.v.01'), Synset('murder.v.01')]]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit[17].hypernym_paths() ##'professorship.n.01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7e43e092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "hit1 = swn.senti_synset('touch.n.05')\n",
    "print(hit1.pos_score())\n",
    "print(hit1.neg_score())\n",
    "print(hit1.obj_score())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d2c451ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.625\n",
      "0.375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hit2 = swn.senti_synset('murder.v.01')\n",
    "print(hit2.pos_score())\n",
    "print(hit2.neg_score())\n",
    "print(hit2.obj_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45aec6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
